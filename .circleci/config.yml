version: 2
jobs:

  build:
    environment:
      TZ: "/usr/share/zoneinfo/America/Los_Angeles"
      SCRATCH: "/scratch"
    docker:
      - image: docker:18.01.0-ce-git
    working_directory: /tmp/src/niworkflows
    steps:
      - run:
          name: Install parallel gzip and python3
          command: |
            apk add --no-cache pigz python3
      - restore_cache:
          keys:
            - docker-v1-{{ .Branch }}-{{ epoch }}
            - docker-v1-{{ .Branch }}-
            - docker-v1-master-
            - docker-v1-
          paths:
            - /tmp/cache/docker.tar.gz
      - checkout
      - setup_remote_docker
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Build Docker image
          no_output_timeout: 60m
          command: |
            e=1 && for i in {1..5}; do
              docker build \
                --cache-from=niworkflows:py3 \
                --rm=false \
                -t niworkflows:py3 \
                --build-arg BUILD_DATE=`date -u +"%Y-%m-%dT%H:%M:%SZ"` \
                --build-arg VCS_REF=`git rev-parse --short HEAD` . \
              && e=0 && break || sleep 15
            done && [ "$e" -eq "0" ]
      - run:
          name: Docker save
          no_output_timeout: 40m
          command: |
            mkdir -p /tmp/cache
            docker save ubuntu:xenial-20161213 niworkflows:py3 \
            | pigz -8 -p 3 > /tmp/cache/docker.tar.gz
      - save_cache:
          key: docker-v1-{{ .Branch }}-{{ epoch }}
          paths:
            - /tmp/cache/docker.tar.gz

      # - persist_to_workspace:
      #     root: /tmp
      #     paths:
      #       - cache/docker.tar.gz

  get_data:
    machine:
      # Ubuntu 14.04 with Docker 17.10.0-ce
      image: circleci/classic:201711-01
    working_directory: /home/circleci/data
    steps:
      - restore_cache:
          keys:
            - data-v1-{{ epoch }}
            - data-v1-
      - run:
          name: Get test data from ds000003
          command: |
            mkdir -p /tmp/data
            if [[ ! -d /tmp/data/ds003_downsampled ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O ds003_downsampled.tar.gz "https://files.osf.io/v1/resources/fvuh8/providers/osfstorage/57f328f6b83f6901ef94cf70"
              tar xvzf ds003_downsampled.tar.gz -C /tmp/data/
            else
              echo "Dataset ds000003 was cached"
            fi
      - run:
          name: Get BIDS test data stub
          command: |
            mkdir -p /tmp/data
            if [[ ! -d /tmp/data/BIDS-examples-1-enh-ds054 ]]; then
              wget --retry-connrefused --waitretry=5 --read-timeout=20 --timeout=15 -t 0 -q \
                -O BIDS-examples-1-enh-ds054.zip "http://github.com/chrisfilo/BIDS-examples-1/archive/enh/ds054.zip"
              unzip BIDS-examples-1-enh-ds054.zip -d /tmp/data/
            else
              echo "BIDS stub was cached"
            fi
      - run:
          name: Store FreeSurfer license file
          command: |
            mkdir -p /tmp/fslicense
            printf "$FS_LICENSE_CONTENT" | base64 -d  >> /tmp/fslicense/license.txt
      - persist_to_workspace:
          root: /tmp
          paths:
            - data
            - fslicense
      - save_cache:
         key: data-v1-{{ epoch }}
         paths:
            - /tmp/data


  test_pytest:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/tests
    steps:
      - attach_workspace:
          at: /tmp
      - restore_cache:
          keys:
            - docker-v1-{{ .Branch }}-{{ epoch }}
            - docker-v1-{{ .Branch }}-
            - docker-v1-master-
            - docker-v1-
      - checkout:
          path: /tmp/src/niworkflows
      - run:
          name: Load Docker image layer cache
          no_output_timeout: 30m
          command: |
            docker info
            set +o pipefail
            if [ -f /tmp/cache/docker.tar.gz ]; then
              sudo apt update && sudo apt -y install pigz
              pigz -d --stdout /tmp/cache/docker.tar.gz | docker load
              docker images
            fi
      - run:
          name: Set PR number
          command: |
            echo 'export CIRCLE_PR_NUMBER="${CIRCLE_PR_NUMBER:-${CIRCLE_PULL_REQUEST##*/}}"' >> $BASH_ENV
            source $BASH_ENV
            echo $CIRCLE_PR_NUMBER
      - run:
          name: Get codecov
          command: python -m pip install codecov
      - run:
          name: Run unit tests
          no_output_timeout: 2h
          command: |
            sudo setfacl -d -m group:ubuntu:rwx $PWD
            sudo setfacl -m group:ubuntu:rwx $PWD
            docker run -it --rm=false \
              -e TEST_DATA_HOME=/data -v /tmp/data:/data \
              -v ${PWD}:/tmp niworkflows:py3 \
              pytest --junit-xml=/tmp/pytest.xml \
                     --cov niworkflows --cov-report xml:/tmp/unittests.xml \
                     --ignore=/src/niworkflows/niworkflows/tests/ \
                     --ignore=/src/niworkflows/niworkflows/interfaces/ants.py \
                     /src/niworkflows/niworkflows

      - run:
          name: Submit unit test coverage
          command: |
            python -m codecov --file unittests.xml --root /tmp/src/niworkflows \
                --flags unittests -e CIRCLE_JOB

      - run:
          name: Run reportlet tests
          no_output_timeout: 2h
          command: |
            docker run -it --rm=false \
              -e SAVE_CIRCLE_ARTIFACTS="/tmp" \
              -e TEST_DATA_HOME=/data -v /tmp/data:/data \
              -v /tmp/fslicense/license.txt:/opt/freesurfer/license.txt:ro \
              -v ${PWD}:/tmp niworkflows:py3 \
              pytest -n auto --junit-xml=/tmp/reportlets.xml \
                     --cov niworkflows --cov-report xml:/tmp/reportlets.xml \
                     /src/niworkflows/niworkflows/tests/
      - run:
          name: Submit reportlet test coverage
          command: |
            python -m codecov --file reportlets.xml --root /tmp/src/niworkflows \
                --flags reportlettests -e CIRCLE_JOB

      - store_artifacts:
          path: /tmp/tests

      - store_test_results:
          path: /tmp/tests

  test_package:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/niworkflows
    steps:
      - checkout
      - run: pyenv local 3.5.2
      - run:
          name: Install build depends
          command: python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1" twine docutils
      - run:
          name: Build and check
          command: |
            python3 setup.py check -r -s
            python3 setup.py sdist bdist_wheel
            python3 -m twine check dist/*
      - run:
          name: Validate version
          command: |
            THISVERSION=$( python3 get_version.py )
            python3 -m pip install dist/*.whl
            mkdir empty
            cd empty
            INSTALLED=$( python3 -c 'import niworkflows; print(niworkflows.__version__)' )
            test "${CIRCLE_TAG:-$THISVERSION}" == "$INSTALLED"

  deploy:
    machine:
      image: circleci/classic:201711-01
    working_directory: /tmp/src/niworkflows
    steps:
      - checkout
      - run: pyenv local 3.5.2
      - run:
          name: Install build depends
          command: python3 -m pip install "setuptools>=30.3.0" "pip>=10.0.1" twine docutils
      - run:
          name: Build and check
          command: |
            python3 setup.py check -r -s
            python3 setup.py sdist bdist_wheel
            python3 -m twine check dist/*
      - run:
          name: Validate version
          command: |
            THISVERSION=$( python3 get_version.py )
            python3 -m pip install dist/*.tar.gz
            mkdir empty
            cd empty
            INSTALLED=$( python3 -c 'import niworkflows; print(niworkflows.__version__)' )
            test "${CIRCLE_TAG:-$THISVERSION}" == "$INSTALLED"
      - run:
          name: Upload to PyPi
          command: |
            python3 -m twine upload dist/*

workflows:
  version: 2
  build_test_deploy:
    jobs:
      - build:
          filters:
            tags:
              only: /.*/
      - get_data:
          filters:
            tags:
              only: /.*/
      - test_package:
          filters:
            tags:
              only: /.*/

      - test_pytest:
          requires:
            - build
            - get_data
          filters:
            branches:
              ignore: /docs?\/.*/
            tags:
              only: /.*/
      - deploy:
          requires:
            - test_pytest
            - test_package
          filters:
            branches:
              ignore: /.*/
            tags:
              only: /.*/
